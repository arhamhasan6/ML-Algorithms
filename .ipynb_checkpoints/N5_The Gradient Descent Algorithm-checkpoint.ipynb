{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(derivative_func, learning_rate=0.02, \n",
    "                     initial_value=0.5, precision=0.001, max_iter=300):\n",
    "    t=initial_value\n",
    "    t_list=[]\n",
    "\n",
    "    for i in range(1,max_iter+1):\n",
    "        t_list.append(t)\n",
    "        t = t - learning_rate * derivative_func(t)\n",
    "        \n",
    "        if abs(learning_rate * derivative_func(t))<=precision:\n",
    "        #if derivative_func(x)==0:\n",
    "            break\n",
    "        \n",
    "    return t,t_list,i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### $$ g(t)=t^4-4t^2+5 $$\n",
    "\n",
    "### $$ \\frac{dg(t)}{dt}=4t^3-8t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing the function g(t)\n",
    "def g(t):\n",
    "    return t**4-4*t**2+5\n",
    "\n",
    "#Implementing the derivative of the function g(t)\n",
    "def dg(t):\n",
    "    return 4*t**3-8*t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making data. \n",
    "#The linspace function returns evenly spaced numbers over a specified interval.\n",
    "t_1=np.linspace(-2,2,1000)\n",
    "type(t_1)\n",
    "#t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the function\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(t_1,g(t_1))\n",
    "plt.xlabel('t', fontsize=14)\n",
    "plt.ylabel('g(t)', fontsize=14)\n",
    "plt.title('Cost function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters: initial_value= 0.5, learning_rate= 0.02, precision= 0.0001, max_iter= 1000\n",
    "local_minima,t_list,runs=gradient_descent(dg, initial_value=0.5, \n",
    "        learning_rate=0.02, max_iter=1000, precision=0.0001)\n",
    "print('Local minima occurs at', local_minima)\n",
    "print('Cost at this point is', g(local_minima))\n",
    "print('Slope at this point is', dg(local_minima))\n",
    "print('Loop runs this many times:', runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting search trace on cost function\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(t_1,g(t_1))\n",
    "plt.xlabel('t', fontsize=14)\n",
    "plt.ylabel('g(t)', fontsize=14)\n",
    "plt.title('Cost function')\n",
    "plt.scatter(t_list,g(np.array(t_list)), color='red',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK FOR YOU\n",
    "Repeat after making the following changes and observe the results:\n",
    "\n",
    "1. In implementation of gradient descent, replace the statment 'if abs(learning_rate * derivative_func(x))<=precision:' with 'if derivative_func(x_old)==0:'. Now the calling code again and observe the results.\n",
    "2. Change initial value to -0.5, 1.5, 5, 50, 0.\n",
    "3. Change learning rate to 0.002, 0.2, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Float Value in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.float_info.max\n",
    "#This is the max value of float that can be habdled by the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting cost function against iterations\n",
    "\n",
    "#Low learning rate (0.0005)\n",
    "low_local_minimum,low_t_list,low_runs=gradient_descent(dg,initial_value=3,precision=0.0001, \n",
    "                                                       max_iter=100,learning_rate=0.0005)\n",
    "n=list(range(1,101)) #since 100 iterations were run\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(n,g(np.array(low_t_list)),color='lightgreen')\n",
    "plt.xlabel('Iterations', fontsize=18)\n",
    "plt.ylabel('Cost function', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.scatter(n,g(np.array(low_t_list)), color='lightgreen',alpha=0.8)\n",
    "\n",
    "#Medium learning rate (0.001)\n",
    "mid_local_minimum,mid_t_list,mid_runs=gradient_descent(dg,initial_value=3,precision=0.0001,\n",
    "                                                       max_iter=100,learning_rate=0.001)\n",
    "n=list(range(1,101))\n",
    "plt.plot(n,g(np.array(mid_t_list)),color='hotpink')\n",
    "plt.scatter(n,g(np.array(mid_t_list)), color='hotpink',alpha=0.8)\n",
    "\n",
    "#High learning rate (0.002)\n",
    "high_local_minimum,high_t_list,high_runs=gradient_descent(dg,initial_value=3,precision=0.0001,\n",
    "                                                          max_iter=100,learning_rate=0.002)\n",
    "n=list(range(1,101))\n",
    "plt.plot(n,g(np.array(high_t_list)),color='steelblue')\n",
    "plt.scatter(n,g(np.array(high_t_list)), color='steelblue',alpha=0.8)\n",
    "\n",
    "#Very very high learning rate (0.25)\n",
    "insane_local_minimum,insane_t_list,insane_runs=gradient_descent(dg,initial_value=1.9,precision=0.0001,\n",
    "                                                                max_iter=100,learning_rate=0.25)\n",
    "n=list(range(1,101))\n",
    "plt.plot(n,g(np.array(insane_t_list)),color='red')\n",
    "plt.scatter(n,g(np.array(insane_t_list)), color='red',alpha=0.8)\n",
    "\n",
    "plt.legend(['0.0005','0.001','0.002','0.25'],title='Learning Rate',title_fontsize=14, fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "### $$ h(t)=t^5-2t^4+2 $$\n",
    "### $$ \\frac{dh(t)}{dt}=5t^4-8t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing the function h(x)\n",
    "def h(t):\n",
    "    return t**5-2*t**4+2\n",
    "\n",
    "#Implementing the derivative of the function h(x)\n",
    "def dh(t):\n",
    "    return 5*t**4-8*t**3\n",
    "\n",
    "#Making data\n",
    "t_2=np.linspace(-2.5,2.5,1000)\n",
    "\n",
    "#Visualizing the function\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlim(-1.2, 2.5)\n",
    "plt.ylim(-1, 4)\n",
    "plt.plot(t_2,h(t_2))\n",
    "plt.xlabel('t', fontsize=14)\n",
    "plt.ylabel('h(t)', fontsize=14)\n",
    "plt.title('Cost function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running gradient descent and plotting the results\n",
    "local_minima,t_list,runs=gradient_descent(dh,initial_value= 1, learning_rate= 0.02, precision= 0.001,max_iter= 20)\n",
    "    \n",
    "print('Local minima occures at ', local_minima)\n",
    "print('Cost at this point is ', h(local_minima))\n",
    "print('Slope at this point is ', dh(local_minima))\n",
    "print('Loop runs this many times: ', runs)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlim(-1.2, 2.5)\n",
    "plt.ylim(-1, 4)\n",
    "plt.plot(t_2,h(t_2))\n",
    "plt.xlabel('t', fontsize=14)\n",
    "plt.ylabel('h(t)', fontsize=14)\n",
    "plt.title('Cost function')\n",
    "plt.scatter(t_list,h(np.array(t_list)), color='red',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK FOR YOU\n",
    "Repeat after making the following changes and observe the results:\n",
    "1. initial_value= -0.8, max_iter= 8\n",
    "2. initial_value= -0.8, learning_rate= 0.02, precision= 0.001,max_iter= 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "The following cost function has 2 parameters.\n",
    "### $$ f(t1,t2)=\\frac{1}{3^{-t1^2-t2^2}+1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing the function f(t1,t2)\n",
    "def f(t1,t2):\n",
    "    return 1/(3**(-t1**2-t2**2)+1)\n",
    "\n",
    "#Making data for t1 and t2\n",
    "t1=np.linspace(-2,2,200)\n",
    "t2=np.linspace(-2,2,200)\n",
    "t1,t2=np.meshgrid(t1,t2) \n",
    "#meshgrid converts t1 and t2 into 2D arrays, as required by the plotting function plot_surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a 3D graph\n",
    "fig=plt.figure(figsize=[16,12])\n",
    "ax=plt.axes(projection='3d')\n",
    "ax.set_xlabel('t1', fontsize=16)\n",
    "ax.set_ylabel('t2', fontsize=16)\n",
    "ax.set_zlabel('Cost - f(t1,t2)', fontsize=16)\n",
    "ax.plot_surface(t1,t2,f(t1,t2), alpha=0.4, cmap='summer') \n",
    "#Explore other colormaps\n",
    "#Website for color choices: materialpalette.com\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial derivatives for $$ f(t1,t2)=\\frac{1}{3^{-t1^2-t2^2}+1} $$ w.r.t. t1 and t2\n",
    "\n",
    "$$ \\frac{\\partial f(t1,t2)}{\\partial dt1} = \\frac{2t1.ln(3).3^{-t1^2-t2^2}}{({3^{-t1^2-t2^2}}+1)^2} $$\n",
    "$$ \\frac{\\partial f(t1,t2)}{\\partial dt2} = \\frac{2t2.ln(3).3^{-t1^2-t2^2}}{({3^{-t1^2-t2^2}}+1)^2} $$\n",
    "\n",
    "Use online tools for finsing derivatives.\n",
    "One website is https://www.symbolab.com/solver/derivative-calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing partial derivatives\n",
    "def pdfx(t1,t2):\n",
    "    return 2*t1*log(3)*(3**(-t1**2-t2**2))/(3**(-t1**2-t2**2)+1)**2\n",
    "def pdfy(t1,t2):\n",
    "    return 2*t2*log(3)*(3**(-t1**2-t2**2))/(3**(-t1**2-t2**2)+1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom implementation of gradient descent for two parameters\n",
    "learning_rate = 0.1\n",
    "max_iter = 20000\n",
    "initial_t1 = 1.8\n",
    "initial_t2=1.5\n",
    "precision=0.000001\n",
    "\n",
    "t1_old=initial_t1\n",
    "t2_old=initial_t2\n",
    "\n",
    "t1_list=[]\n",
    "t2_list=[]\n",
    "for i in range (1,max_iter+1):\n",
    "    t1_new = t1_old - learning_rate * pdfx(t1_old,t2_old)\n",
    "    t2_new = t2_old - learning_rate * pdfy(t1_old,t2_old)\n",
    "    \n",
    "    t1_list.append(t1_old)\n",
    "    t2_list.append(t2_old)\n",
    "\n",
    "    t1_old=t1_new\n",
    "    t2_old=t2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the 3D graph\n",
    "fig=plt.figure(figsize=[16,12])\n",
    "ax=plt.axes(projection='3d')\n",
    "ax.set_xlabel('t1', fontsize=16)\n",
    "ax.set_ylabel('t2', fontsize=16)\n",
    "ax.set_zlabel('Cost - f(t1,t2)', fontsize=16)\n",
    "ax.plot_surface(t1,t2,f(t1,t2), alpha=0.4, cmap='summer')\n",
    "t1_list=np.array(t1_list)\n",
    "t2_list=np.array(t2_list)\n",
    "ax.scatter(t1_list,t2_list,f(t1_list,t2_list), alpha=0.4, s=50, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
