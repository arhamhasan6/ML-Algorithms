{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Creating and Visualizing data for 1 feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making and visualizing data\n",
    "#X=np.array([1,2,3,4,5]).reshape(-1,1)\n",
    "#y=np.array([20, 45, 56, 64, 70]).reshape(-1,1)\n",
    "X=np.array([300,170,288,360,319,330,520,345,399,479]).reshape(-1,1)\n",
    "y=np.array([305000,270000,360000,370000,379000,405000,407500,450000,450000,485000]).reshape(-1,1)\n",
    "\n",
    "#Plotting the data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above plot we can see that distribution of data is somewhat non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression\n",
    "$$y=\\theta_0+\\theta_1X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model1=LinearRegression()\n",
    "model1.fit(X,y)\n",
    "\n",
    "#Plotting the fit line over the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "plt.plot(X,model1.predict(X),color='red',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "print('R_square score:',model1.score(X,y))\n",
    "print('theta_0:',model1.intercept_[0])\n",
    "print('theta_1:',model1.coef_[0][0])\n",
    "print('Number of non-zero features:',np.sum(model1.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Polynomial Regression with degree 2 polynomial\n",
    "$$y=\\theta_0+\\theta_1X+\\theta_2X^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of polynomial regression is a two-step process. \n",
    "First, we transform our data into a polynomial using the PolynomialFeatures function from sklearn and,\n",
    "then use linear regression to fit the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting linear function to polynomial function of degree 2\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_poly2 = poly2.fit_transform(X)\n",
    "#X_poly is ndarray having three columns: \n",
    "#First one is a constant to represent X_0, \n",
    "#Second is X_1=X \n",
    "#Third is X_2=X**2, simply square of X\n",
    "X_poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting ndarray to DataFrame and dropping the constant (first column)\n",
    "X_poly2=pd.DataFrame(X_poly2)\n",
    "X_poly2=X_poly2.drop([0],axis=1)\n",
    "X_poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now X_poly has two feature: X_1=X and X_2=X**2\n",
    "\n",
    "#now fitting linear model to it\n",
    "model2=LinearRegression()\n",
    "model2.fit(X_poly2,y)\n",
    "\n",
    "#generating data for line plot, for smoother curve\n",
    "X_data=np.linspace(X.min(),X.max(),300).reshape(-1,1) \n",
    "X_data_poly2 = pd.DataFrame(poly2.fit_transform(X_data)).drop([0],axis=1)\n",
    "X_data_poly2\n",
    "\n",
    "\n",
    "#Plotting the fit line over the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "#plt.plot(X,model2.predict(X_poly2),color='red',linewidth=4)\n",
    "plt.plot(X_data,model2.predict(X_data_poly2),color='red',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "print('R_squared score:',model2.score(X_poly2,y))\n",
    "print('theta_0:',model2.intercept_[0])\n",
    "print('theta_1:',model2.coef_[0])\n",
    "print('Number of non-zero features:',np.sum(model2.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#An alternate, shorter form form Model 2\n",
    "model2a=make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\n",
    "model2a.fit(X,y)\n",
    "\n",
    "#Plotting the fit line over the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "plt.plot(X_data,model2a.predict(X_data),color='red',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "print('R_square score:',model2a.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Polynomial Regression with degree 9 polynomial\n",
    "$$y=\\theta_0+\\theta_1X+\\theta_2X^2+\\theta_3X^3+\\theta_4X^4+\\theta_5X^5+\\theta_6X^6+\\theta_7X^7+\\theta_8X^8+\\theta_9X^9$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Converting linear function to polynomial function of degree 9 using the longer method\n",
    "\n",
    "poly3 = PolynomialFeatures(degree=9)\n",
    "X_poly3 = poly3.fit_transform(X)\n",
    "\n",
    "X_poly3=pd.DataFrame(X_poly3)\n",
    "X_poly3=X_poly3.drop([0],axis=1)\n",
    "\n",
    "model3=LinearRegression()\n",
    "model3.fit(X_poly3,y)\n",
    "\n",
    "#Generating data for line plot, for smoother curve\n",
    "X_data=np.linspace(X.min(),X.max(),300).reshape(-1,1) \n",
    "X_data_poly3 = pd.DataFrame(poly3.fit_transform(X_data)).drop([0],axis=1)\n",
    "\n",
    "#Plotting the fit line over the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "plt.plot(X_data,model3.predict(X_data_poly3),color='red',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "print('R_square score:',model3.score(X_poly3,y))\n",
    "print('theta_0:',model3.intercept_[0])\n",
    "print('theta_1:',model3.coef_[0])\n",
    "print('Number of non-zero features:',np.sum(model3.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#An alternate, shorter form form Model 3\n",
    "model3a=make_pipeline(PolynomialFeatures(degree=9),LinearRegression())\n",
    "model3a.fit(X,y)\n",
    "\n",
    "#Plotting the fit line over the scatter plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,y)\n",
    "plt.title('X vs y',fontsize=14)\n",
    "plt.xlabel('X',fontsize=14)\n",
    "plt.ylabel('y',fontsize=14)\n",
    "plt.plot(X_data,model3a.predict(X_data),color='red',linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "print('R_squared score:',model3a.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Creating and Visualizing data for Multi-feature model\n",
    "### Revisiting the Boston house pricing example again\n",
    "- The models in Problem 2 are number 4 and 5 just to avoid name clashes with models of problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and visualizing data\n",
    "boston_dataset = load_boston()\n",
    "dataset = pd.DataFrame(data=boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "dataset['PRICE'] = boston_dataset.target\n",
    "target = dataset['PRICE']\n",
    "features = dataset.drop('PRICE', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model4 = LinearRegression()\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "print('Training data r-square:', model4.score(X_train, y_train))\n",
    "print('Test data r-square:', model4.score(X_test, y_test))\n",
    "print('Number of non-zero features:',np.sum(model4.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Polynomial Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "deg=9 #try 3\n",
    "X_train_poly2=PolynomialFeatures(degree=deg).fit_transform(X_train)\n",
    "X_train_poly2=pd.DataFrame(X_train_poly2)\n",
    "X_train_poly2=X_train_poly2.drop([0],axis=1)\n",
    "model5=LinearRegression()\n",
    "model5.fit(X_train_poly2,y_train)\n",
    "\n",
    "print('Training data r-square:', model5.score(X_train_poly2, y_train))\n",
    "X_test_poly2=PolynomialFeatures(degree=deg).fit_transform(X_test)\n",
    "X_test_poly2=pd.DataFrame(X_test_poly2)\n",
    "X_test_poly2=X_test_poly2.drop([0],axis=1)\n",
    "print('Test data r-square:', model5.score(X_test_poly2, y_test))\n",
    "print('Number of non-zero features:',np.sum(model5.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
